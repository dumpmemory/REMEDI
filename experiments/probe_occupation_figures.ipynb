{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3562a4b",
   "metadata": {},
   "source": [
    "Visualize probe accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20457e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "probe_accuracies_file = pathlib.Path('../results/probe_occupations/gpt-j-6B/accuracies.json')\n",
    "with probe_accuracies_file.open('r') as handle:\n",
    "    accuracies = json.load(handle)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "layers_by_target = defaultdict(list)\n",
    "accuracies_by_target = defaultdict(list)\n",
    "\n",
    "for target in ('occupation', 'predictions'):\n",
    "    true_layers = []\n",
    "    true_accuracies = []\n",
    "    for entry in sorted(accuracies, key=lambda entry: entry['layer']):\n",
    "        if 'top-k' not in entry or entry['top-k'] != 3:\n",
    "            continue\n",
    "        if entry['target'] != target:\n",
    "            continue\n",
    "        layers_by_target[target].append(entry['layer'])\n",
    "        accuracies_by_target[target].append(entry['accuracy'])\n",
    "\n",
    "print(layers_by_target['occupation'])\n",
    "print(accuracies_by_target['occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "for target in ('occupation', 'predictions'):\n",
    "    plt.figure()\n",
    "    plt.bar(layers_by_target[target], accuracies_by_target[target])\n",
    "    plt.title(f'probe {target}')\n",
    "    plt.xlabel('layer')\n",
    "    plt.ylabel('probe accuracy')\n",
    "    plt.yticks(tuple(numpy.arange(0, 1.1, .1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a460aa9c",
   "metadata": {},
   "source": [
    "Visualize discourse probing results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "results_file = pathlib.Path(\n",
    "    '../data/gpt-j-6B/occupations-discourse-predicted.json')\n",
    "with results_file.open('r') as handle:\n",
    "    results = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8151be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "corrects, totals = defaultdict(int), defaultdict(int)\n",
    "for result in results:\n",
    "    condition = frozenset(result['condition'].items())\n",
    "    corrects[condition] += result['occupation'] in result['predictions']\n",
    "    totals[condition] += 1\n",
    "accuracies = {key: correct / totals[key] for key, correct in corrects.items()}\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b3a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def condition_set_to_text(condition):\n",
    "    condition = dict(condition)\n",
    "    result = f'{condition[\"context\"]} ctx'\n",
    "    if condition['entity'] == 'famous':\n",
    "        result = f'{result}, {condition[\"occupation\"]} occ'\n",
    "    return result\n",
    "\n",
    "xs_by_entity, ys_by_entity = defaultdict(list), defaultdict(list)\n",
    "for entity in ('famous', 'generic'):\n",
    "    for occ in ('correct', 'random'):\n",
    "        for condition, accuracy in accuracies.items():\n",
    "            condition = dict(condition)\n",
    "            if condition['entity'] != entity or condition['occupation'] != occ:\n",
    "                continue\n",
    "            xs_by_entity[entity, occ].append(condition_set_to_text(condition))\n",
    "            ys_by_entity[entity, occ].append(accuracy)\n",
    "xs_by_entity, ys_by_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae48b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "def plot(entity, occupation, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(xs_by_entity[entity, occupation], ys_by_entity[entity, occupation])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('model accuracy')\n",
    "    plt.yticks(tuple(numpy.arange(0, 1.1, .1)))\n",
    "\n",
    "plot('famous', 'correct', 'famous entity, correct occupation')\n",
    "plot('famous', 'random', 'famous entity, random occupation')\n",
    "plot('generic', 'random', 'generic entity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7a2dd9",
   "metadata": {},
   "source": [
    "# Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fcf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "results_file = pathlib.Path(\n",
    "    '../results/probe_discourse/gpt-j-6B/occupations-discourse-probed.json')\n",
    "with results_file.open('r') as handle:\n",
    "    results = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "accuracies_by_layer = {}\n",
    "for layer in tqdm(range(29)):\n",
    "    corrects, totals = defaultdict(int), defaultdict(int)\n",
    "    for result in results:\n",
    "        condition = frozenset(result['condition'].items())\n",
    "        corrects[condition] += result['predictions'][0] in result['probed'][str(layer)][:3]\n",
    "        totals[condition] += 1\n",
    "    accuracies_by_layer[layer] = {key: correct / totals[key] for key, correct in corrects.items()}\n",
    "\n",
    "accuracies = defaultdict(dict)\n",
    "for layer, accuracies_by_condition in accuracies_by_layer.items():\n",
    "    for condition, accuracy in accuracies_by_condition.items():\n",
    "        accuracies[condition][layer] = accuracy\n",
    "\n",
    "outputs = {}\n",
    "for condition, by_layer in accuracies.items():\n",
    "    layer, accuracy = max(by_layer.items(), key=lambda kv: kv[-1])\n",
    "    outputs[condition] = {'layer': layer, 'accuracy': accuracy}\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a9584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
