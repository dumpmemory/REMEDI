{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4dbfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d4d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import dataset_utils, model_utils\n",
    "\n",
    "device = \"cuda:4\"\n",
    "batch_size = 32\n",
    "layer = 15\n",
    "mt = model_utils.load_model(\"gpt2-xl\", fp16=True)\n",
    "mt.model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fd6df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_utils.load_dataset(\"counterfact\", split=\"train[:5000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2cf7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import editors, precompute\n",
    "import importlib\n",
    "importlib.reload(editors)\n",
    "importlib.reload(precompute)\n",
    "layer = 10\n",
    "splits = dataset_utils.maybe_train_test_split(dataset, test_size=.1)\n",
    "splits = precompute.editor_inputs_from_dataset(\n",
    "    mt=mt,\n",
    "    dataset=splits,\n",
    "    batch_size=batch_size,\n",
    "    layers=[layer],\n",
    "    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be958d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import editors\n",
    "\n",
    "import importlib\n",
    "importlib.reload(editors)\n",
    "\n",
    "editor = editors.BiaffineEditor(mt=mt, layer=layer).to(device)\n",
    "editor.fit(\n",
    "    dataset=splits,\n",
    "    device=device,\n",
    "    batch_size=batch_size,\n",
    "    lr=1e-4,\n",
    "    max_epochs=5,\n",
    "    lam_adv=None,\n",
    "    lam_kl=None,\n",
    "#     lam_kl=.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5540877",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(editors)\n",
    "entity = \"Jane Smith\"\n",
    "attribute = \"has an MD from Harvard Medical School\"\n",
    "context = \"{entity} {attribute}\".format(entity=entity, attribute=attribute)\n",
    "prompt = \"{entity} works in a\".format(entity=entity)\n",
    "\n",
    "import torch\n",
    "\n",
    "with editors.apply(editor, alpha=1, device=device) as edited:\n",
    "    outputs = edited.model.generate({\n",
    "        \"entity\": [entity],\n",
    "        \"context\": [context],\n",
    "        \"prompt\": [prompt],\n",
    "        \"attribute\": [attribute],\n",
    "    }, max_new_tokens=20)\n",
    "print(mt.tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0112e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(editors)\n",
    "# importlib.reload(tokenizer_utils)\n",
    "editor.half()\n",
    "results = editor.evaluate(splits[\"test\"], alpha=1, batch_size=batch_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = results.results[2]\n",
    "print(result.sample[\"target_mediated\"], \"vs\", result.sample[\"target_unmediated\"])\n",
    "print(result.before_generations)\n",
    "print(result.before_top_tokens)\n",
    "print(result.after_generations)\n",
    "print(result.after_top_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83531666",
   "metadata": {},
   "source": [
    "# Pretrained Editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918fc135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import dataset_utils, model_utils\n",
    "\n",
    "device = \"cuda:5\"\n",
    "mt = model_utils.load_model(\"gpt2-xl\", fp16=False)\n",
    "mt.model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f795020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import editors\n",
    "\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54592d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"linear_with_loss_terms\"\n",
    "\n",
    "entity = \"Jane\"\n",
    "prompt = \"wrote the famous song\"\n",
    "attribute = \"is the lead singer of the band Nirvana\"\n",
    "\n",
    "for layer in range(25):\n",
    "    state_dict = torch.load(\n",
    "        f\"../results/{experiment}/linear/{layer}/weights.pth\",\n",
    "        map_location=device)\n",
    "    editor = editors.LinearEditor(mt=mt, layer=layer,\n",
    "                                  use_entity=False,\n",
    "                                  edit_last_entity_token=True)\n",
    "    editor.load_state_dict(state_dict)\n",
    "    editor.to(device)\n",
    "\n",
    "    with editors.apply(editor, device=device) as mt_edit:\n",
    "        outputs = mt_edit.model.generate({\n",
    "            \"entity\": entity,\n",
    "            \"prompt\": f\"{entity} {prompt}\",\n",
    "            \"context\": f\"{entity} {attribute}\",\n",
    "            \"attribute\": attribute,\n",
    "        }, max_new_tokens=20)\n",
    "    print(layer, mt.tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41c656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
