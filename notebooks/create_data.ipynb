{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1629e8c4",
   "metadata": {},
   "source": [
    "# Load entities and occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a750ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "raw = []\n",
    "\n",
    "root = pathlib.Path('/raid/lingo/dez/code/knowledge-fluidity/data/TaskBenchData/atomic')\n",
    "for directory in root.glob('wiki{occupation(0)}'):\n",
    "    file = directory / 'all.jsonl'\n",
    "    with file.open('r') as handle:\n",
    "        for line in tqdm(handle.readlines(), desc=file.parent.name):\n",
    "            raw.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3563f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfbcbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "occupations = [\n",
    "    occ\n",
    "    for occ, _ in\n",
    "    collections.Counter([entity['train_tgts'][0]['ent_name'] for entity in raw]).most_common()[:150]\n",
    "]\n",
    "occupations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f8585",
   "metadata": {},
   "source": [
    "# Create contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baaf5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "device = 'cuda:1'\n",
    "roberta = None\n",
    "bart = None\n",
    "\n",
    "# tokenizer = transformers.AutoTokenizer.from_pretrained('roberta-base')\n",
    "# roberta = transformers.AutoModelForMaskedLM.from_pretrained('roberta-base').to(device)\n",
    "\n",
    "tokenizer = transformers.BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "bart = transformers.BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\",\n",
    "                                                                 forced_bos_token_id=0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_templates = (\n",
    "    'A {occupation} works at a <mask>',  # Location\n",
    "    'A {occupation} uses a <mask>',  # Tool\n",
    "    'The job of a {occupation} is to <mask>', # Role\n",
    "    'A {occupation} has a degree in <mask>',  # Training\n",
    ")\n",
    "context_prompts = {\n",
    "    occupation: [\n",
    "        template.format(occupation=occupation)\n",
    "        for template in context_templates\n",
    "    ]\n",
    "    for occupation in occupations\n",
    "}\n",
    "context_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "loader = torch.utils.data.DataLoader(tuple(context_prompts.items()), batch_size=32)\n",
    "\n",
    "fillers = defaultdict(list)\n",
    "for occs, prompts_by_kind in tqdm(loader):\n",
    "    for prompts in prompts_by_kind:\n",
    "        inputs = tokenizer(list(prompts), return_tensors='pt', padding='longest').to(device)\n",
    "        if roberta is not None:\n",
    "            with torch.inference_mode():\n",
    "                outputs = roberta(**inputs)\n",
    "            indices = inputs.attention_mask.sum(dim=-1) - 3\n",
    "            logits = outputs.logits[torch.arange(len(indices)), indices.squeeze()]\n",
    "            predictions = logits.argmax(dim=-1)\n",
    "            assert len(occs) == len(predictions)\n",
    "            for occupation, ids in zip(occs, predictions):\n",
    "                token = tokenizer.decode(ids.squeeze().tolist()).strip()\n",
    "                fillers[occupation].append(token)\n",
    "        else:\n",
    "            assert bart is not None\n",
    "            with torch.inference_mode():\n",
    "                outputs = bart.generate(**inputs)\n",
    "\n",
    "            indices = inputs.attention_mask.sum(dim=-1) - 1\n",
    "            strings = []\n",
    "            for ids, start in zip(outputs, indices):\n",
    "                string = tokenizer.decode(ids[start:], skip_special_tokens=True).strip()\n",
    "                strings.append(string)\n",
    "            assert len(occs) == len(strings)\n",
    "            for occupation, string in zip(occs, strings):\n",
    "                fillers[occupation].append(string.strip(' .;:'))\n",
    "\n",
    "fillers    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53246e4d",
   "metadata": {},
   "source": [
    "A little playground for sanity checking this process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53271944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large\", forced_bos_token_id=0)\n",
    "tok = BartTokenizer.from_pretrained(\"facebook/bart-large\")\n",
    "example_english_phrase = \"An economist's job is to <mask>\"\n",
    "batch = tok(example_english_phrase, return_tensors=\"pt\")\n",
    "generated_ids = model.generate(batch[\"input_ids\"])\n",
    "print(tok.batch_decode(generated_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754eafc5",
   "metadata": {},
   "source": [
    "# Generate discourse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import names_dataset\n",
    "nd = names_dataset.NameDataset()\n",
    "all_us_names = nd.get_top_names(n=100, country_alpha2='US')['US']\n",
    "generic_us_names = [*all_us_names['M'], *all_us_names['F']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90c229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "samples = []\n",
    "for entity in raw:\n",
    "    real_name = entity['inputs'][0]['ent_name']\n",
    "    real_occupation = entity['train_tgts'][0]['ent_name']\n",
    "    if real_occupation not in occupations:\n",
    "        continue\n",
    "        \n",
    "    fake_name = random.choice(generic_us_names)\n",
    "    fake_occupation = random.choice(occupations)\n",
    "\n",
    "    names = {\n",
    "        'real': real_name,\n",
    "        'fake': fake_name,\n",
    "        'none': 'a person',\n",
    "    }\n",
    "\n",
    "    occs = {\n",
    "        'real': real_occupation,\n",
    "        'fake': fake_occupation,\n",
    "    }\n",
    "\n",
    "    context_templates = {\n",
    "        'primary': 'who works as a {occupation}',\n",
    "        'secondary': random.choice([\n",
    "            'who forgot to bring a {tool} to their job at the {location}',\n",
    "            'who works at a {location} and whose job is to {role}',\n",
    "        ]),\n",
    "        'irrelevant': random.choice([\n",
    "            'who climbed a hill',\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    for name_kind, name_text in names.items():\n",
    "        for occ_kind, occ_text in occs.items():\n",
    "            for context_kind, context_template in context_templates.items():\n",
    "                fillers = context_words[occ_text]\n",
    "                context = context_template\\\n",
    "                    .replace('{occupation}', occ_text)\\\n",
    "                    .replace('{location}', fillers[0])\\\n",
    "                    .replace('{tool}', fillers[1])\\\n",
    "                    .replace('{role}', fillers[2])\\\n",
    "                    .replace('{degree}', fillers[3])\n",
    "\n",
    "                text = f'This is a story about {name_text} {context}.'\n",
    "                sample = {\n",
    "                    'condition': {\n",
    "                        'name': name_kind,\n",
    "                        'occupation': occ_kind,\n",
    "                        'context': context_kind,\n",
    "                    },\n",
    "                    'labels': {\n",
    "                        'name': name_text,\n",
    "                        'occupation': occ_text,\n",
    "                    },\n",
    "                    'text': text,\n",
    "                }\n",
    "                samples.append(sample)      \n",
    "                \n",
    "out_file = pathlib.Path('/raid/lingo/dez/code/knowledge-fluidity/probing-discourse.json')\n",
    "with out_file.open('w') as handle:\n",
    "    json.dump(samples, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45305f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[1000:1100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b83a5bc",
   "metadata": {},
   "source": [
    "# Generate probing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb511166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "formats = (\n",
    "    '{prefix}{name} works as a {occupation}.',\n",
    "    '{prefix}{name}, the {occupation}, went to the store.',\n",
    "    '{prefix}{name}, the {occupation}, attended my wedding last Wednesday.',\n",
    "    '{prefix}{name}, the {occupation}, is a close friend of mine',\n",
    "    '{prefix}{name} is tired from working as a {occupation} all day',\n",
    "    # '{prefix}{name} is a busy {occupation}',\n",
    "    '{prefix}{name} dreams of becoming a {occupation}.',\n",
    "    # '{name}',\n",
    ")\n",
    "\n",
    "prefixes = (\n",
    "    ('', 1),\n",
    "    ('My cousin ', 3),\n",
    "    ('My mother ', 3),\n",
    "    ('My father ', 3),\n",
    "    ('My friend ', 3),\n",
    "    ('I met a friend named ', 6),\n",
    "    ('This is a story about how ', 7),\n",
    ")\n",
    "\n",
    "samples = []\n",
    "for _ in range(500000):\n",
    "    name = random.choice(generic_us_names)\n",
    "    occupation = random.choice(occupations)\n",
    "    prefix, token = random.choice(prefixes)\n",
    "    fmt = random.choice(formats)\n",
    "    text = fmt.format(\n",
    "        prefix=prefix,\n",
    "        name=name,\n",
    "        occupation=occupation,\n",
    "    )\n",
    "    sample = {'text': text, 'label': occupation, 'token': token}\n",
    "    samples.append(sample)\n",
    "\n",
    "out_file = pathlib.Path('/raid/lingo/dez/code/knowledge-fluidity/probing-training-generic-names.json')\n",
    "with out_file.open('w') as handle:\n",
    "    json.dump(samples, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdf404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "samples = []\n",
    "for entry in raw:\n",
    "    text = entry['inputs'][0]['ent_name']\n",
    "    occupation = entry['train_tgts'][0]['ent_name']\n",
    "    sample = {'text': text, 'label': occupation}\n",
    "    samples.append(sample)\n",
    "\n",
    "out_file = pathlib.Path('/raid/lingo/dez/code/knowledge-fluidity/probing-training-real-names.json')\n",
    "with out_file.open('w') as handle:\n",
    "    json.dump(samples, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc063f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
