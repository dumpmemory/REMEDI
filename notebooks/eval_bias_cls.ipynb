{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e57957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5327cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e20f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import models\n",
    "\n",
    "device = \"cuda\"\n",
    "mt = models.load_model(\n",
    "    \"EleutherAI/gpt-j-6B\",\n",
    "    fp16=True,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eec7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import data\n",
    "data.disable_caching()\n",
    "test = data.load_dataset(\"biosbias\", split=\"train[5000:6000]\").map(lambda e: {\"target_unmediated\": \"foo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c79cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = data.load_dataset(\"biosbias\", split=\"train\")\n",
    "labels = sorted({sample[\"target_mediated\"] for sample in full_dataset})\n",
    "labels, len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63887551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "label_token_ids = mt.tokenizer(labels, return_tensors=\"pt\", padding=\"longest\").input_ids[:, 0]\n",
    "\n",
    "@torch.inference_mode()\n",
    "def add_model_predictions(e):\n",
    "    inputs = mt.tokenizer(f\"{e['context'].rstrip('.')}. {e['prompt']}\",\n",
    "                          return_tensors=\"pt\").to(device)\n",
    "    outputs = mt.model(**inputs)\n",
    "    dist = torch.log_softmax(outputs.logits[0, -1], dim=-1)[label_token_ids]\n",
    "    return { \"scores\": dist }\n",
    "\n",
    "test = test.map(add_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c561a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "EDITOR_LAYERS = range(20, 27)\n",
    "PROBE_LAYERS = [1] + list(range(15, 27))\n",
    "EDITOR_DIR = Path(\"results/gptj_biosbias_fixed_context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd49992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import precompute\n",
    "precomputed = precompute.classification_inputs_from_dataset(\n",
    "    mt=mt,\n",
    "    dataset=test.map(lambda e: {\"target_unmediated\": e[\"target_mediated\"]}),\n",
    "    device=device,\n",
    "    layers=PROBE_LAYERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb507180",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from src.utils import training_utils\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef\n",
    "\n",
    "for editor_layer in EDITOR_LAYERS:\n",
    "    editor = editors.LinearEditor(mt=mt, layer=editor_layer).to(device)\n",
    "    editor.load_state_dict(\n",
    "        torch.load(\n",
    "            EDITOR_DIR / f\"linear/{editor_layer}/weights.pth\",\n",
    "            map_location=device,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Alternatively: can use attribute representation as the edit direction.\n",
    "    #     editor = editors.IdentityEditor(mt=mt, layer=editor_layer)\n",
    "\n",
    "    for probe_layer in PROBE_LAYERS:\n",
    "        h_es = []\n",
    "        h_dirs = []\n",
    "        for sample in tqdm(precomputed):\n",
    "            h_e = torch.tensor(\n",
    "                sample[f\"prompt_in_context.entity.hiddens.{probe_layer}.last\"],\n",
    "                device=device,\n",
    "            )\n",
    "\n",
    "            with editors.apply(editor, device=device) as edited_mt:\n",
    "                directions = edited_mt.model.compute_edit_directions(\n",
    "                    {\n",
    "                        \"entity\": [sample[\"entity\"]] * len(labels),\n",
    "                        \"prompt\": [f\"{sample['entity']} has the occupation of\"] * len(labels),\n",
    "                        \"context\": [\n",
    "                            f\"{sample['entity']} has the occupation of {label}\"\n",
    "                            if label != sample[\"target_mediated\"].strip()\n",
    "                            else sample[\"context\"]\n",
    "                            for label in labels\n",
    "\n",
    "                        ],\n",
    "                        \"attribute\": [\n",
    "                            f\"has the occupation of {label}\"\n",
    "                            if label != sample[\"target_mediated\"].strip()\n",
    "                            else sample[\"attribute\"]\n",
    "                            for label in labels\n",
    "                        ]\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            h_es.append(h_e)\n",
    "            h_dirs.append(directions)\n",
    "\n",
    "        h_es = torch.stack(h_es).float()\n",
    "        h_es = (h_es - h_es.mean(dim=0, keepdim=True)) / h_es.std(dim=0, keepdim=True)\n",
    "\n",
    "        all_dirs = torch.cat(h_dirs).float()\n",
    "        mu_dirs = all_dirs.mean(dim=0, keepdim=True)\n",
    "        std_dirs = all_dirs.std(dim=0, keepdim=True)\n",
    "        h_dirs = [(dirs - mu_dirs) / std_dirs for dirs in h_dirs]\n",
    "\n",
    "        recalled = []\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for sample, h_e, directions in list(zip(precomputed, h_es, h_dirs)):\n",
    "            scores = h_e[None].mul(directions).sum(dim=-1)\n",
    "\n",
    "            probe_predictions_idx = scores.topk(k=3).indices.squeeze().tolist()\n",
    "            model_predictions_idx = sample[\"scores\"].topk(dim=-1, k=3).indices.squeeze().tolist()\n",
    "            \n",
    "            probe_predictions = [labels[idx] for idx in probe_predictions_idx]\n",
    "            model_prediction = labels[model_predictions_idx[0]]\n",
    "            target = sample[\"target_mediated\"].strip()\n",
    "\n",
    "            y_true.append(model_prediction != target)\n",
    "            y_pred.append(target not in probe_predictions)\n",
    "\n",
    "            recalled.append(target in probe_predictions)\n",
    "\n",
    "        print(\n",
    "            f\"editor_layer={editor_layer}\",\n",
    "            f\"probe_layer={probe_layer}\",\n",
    "            f\"recall@3={sum(recalled) / len(recalled)}\",\n",
    "            f\"f1={f1_score(y_true, y_pred):.2f}\",\n",
    "            f\"mcc={matthews_corrcoef(y_true, y_pred):.2f}\",\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
