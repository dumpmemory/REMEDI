{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad71e920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7183ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from remedi import models\n",
    "\n",
    "device = \"cuda\"\n",
    "mt = models.load_model(\"EleutherAI/gpt-j-6B\", fp16=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de167191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from remedi import data, precompute\n",
    "\n",
    "data.disable_caching()\n",
    "\n",
    "def manually_add_model_correct(dataset, labels):\n",
    "    \n",
    "    def fn(e):\n",
    "        chosen = labels[torch.tensor(e[\"prompt_in_context.other_targets.logp\"]).argmax().item()]\n",
    "        target = e[\"target_mediated\"]\n",
    "        return {\n",
    "            \"prompt_in_context.model_correct\": chosen == target\n",
    "        }\n",
    "    \n",
    "    return dataset.map(fn)\n",
    "\n",
    "\n",
    "def precompute_model_predictions(dataset_name, dataset, version=\"med\"):\n",
    "    assert version in (\"prior\", \"med\")\n",
    "\n",
    "    labels = None\n",
    "    if dataset_name == \"biosbias\":\n",
    "        labels = sorted({x[\"target_mediated\"] for x in dataset})\n",
    "\n",
    "    model_predictions_kwargs = {}\n",
    "    if version == \"prior\":\n",
    "        assert dataset_name == \"counterfact\"\n",
    "        model_predictions_kwargs[\"input_prompt_key\"] = \"prompt\"\n",
    "        model_predictions_kwargs[\"input_target_key\"] = \"target_unmediated\"\n",
    "        model_predictions_kwargs[\"input_comparator_key\"] = \"target_mediated\"\n",
    "    elif version == \"med\":\n",
    "        model_predictions_kwargs[\"input_prompt_key\"] = \"prompt_in_context\"\n",
    "        model_predictions_kwargs[\"input_target_key\"] = \"target_mediated\"\n",
    "        if dataset_name == \"biosbias\":\n",
    "            model_predictions_kwargs[\"other_targets\"] = labels\n",
    "            model_predictions_kwargs[\"input_comparator_key\"] = None\n",
    "        else:\n",
    "            model_predictions_kwargs[\"input_comparator_key\"] = \"target_unmediated\"\n",
    "\n",
    "    dataset = precompute.model_predictions_from_dataset(\n",
    "        dataset=dataset,\n",
    "        mt=mt,\n",
    "        device=device,\n",
    "        **model_predictions_kwargs,\n",
    "    )\n",
    "\n",
    "    if dataset_name == \"biosbias\":\n",
    "        dataset = manually_add_model_correct(dataset, labels)\n",
    "        \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def load_and_preprocess(dataset_name, split=None, layers=None):\n",
    "    assert dataset_name in (\"biosbias\", \"counterfact\")\n",
    "    dataset = data.load_dataset(dataset_name, split=split)\n",
    "    dataset = precompute.classification_inputs_from_dataset(\n",
    "        dataset=dataset,\n",
    "        mt=mt,\n",
    "        device=device,\n",
    "        layers=layers,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e000a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from remedi.utils import training_utils\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "LR = 1e-4\n",
    "PATIENCE = 4\n",
    "BATCH_SIZE = 128\n",
    "MAX_EPOCHS = 10\n",
    "HOLD_OUT = .1\n",
    "\n",
    "# Just some defaults, these change for biosbias\n",
    "EDITOR_LAYER = 1\n",
    "ENTITY_LAYER = 26\n",
    "ENTITY_SOURCE = \"prompt_in_context\"\n",
    "\n",
    "\n",
    "def forward(\n",
    "    probe,\n",
    "    batch,\n",
    "    entity_source=ENTITY_SOURCE,\n",
    "    editor_layer=EDITOR_LAYER,\n",
    "    entity_layer=ENTITY_LAYER,\n",
    "):\n",
    "    h_e = batch[f\"{entity_source}.entity.hiddens.{entity_layer}.last\"].to(device)\n",
    "    h_m = batch[f\"context.attribute.hiddens.{editor_layer}.average\"].to(device)\n",
    "    predictions = probe(h_e, h_m)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_labels(batch, entity_source=ENTITY_SOURCE):\n",
    "    return batch[f\"{entity_source}.model_correct\"].to(device, torch.float)[:, None]\n",
    "\n",
    "\n",
    "def compute_loss(probe, batch, criterion, entity_source=ENTITY_SOURCE, **kwargs):\n",
    "    predictions = forward(probe, batch, entity_source=entity_source, **kwargs)\n",
    "    labels = get_labels(batch, entity_source=entity_source)\n",
    "    loss = criterion(predictions, labels)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def train_probe(\n",
    "    dataset,\n",
    "    entity_source=ENTITY_SOURCE,\n",
    "    editor_layer=EDITOR_LAYER,\n",
    "    entity_layer=ENTITY_LAYER,\n",
    "    lr=LR,\n",
    "    patience=PATIENCE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    hold_out=HOLD_OUT,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    exclude_columns=(),\n",
    "):\n",
    "    hidden_size = mt.model.config.hidden_size\n",
    "    probe = nn.Bilinear(hidden_size, hidden_size, 1).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    stopper = training_utils.EarlyStopping(patience=patience)\n",
    "    optimizer = optim.AdamW(probe.parameters(), lr=lr)\n",
    "    \n",
    "    columns = data.column_names(dataset, exclude=exclude_columns)\n",
    "    with dataset.formatted_as(\"torch\", columns=columns):\n",
    "        train, val = training_utils.random_split(dataset, hold_out=hold_out)\n",
    "        train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val, batch_size=batch_size)\n",
    "\n",
    "        best = probe.state_dict()\n",
    "        for _ in range(max_epochs):\n",
    "            probe.train()\n",
    "            train_loss = 0.\n",
    "            pbar = tqdm(train_loader, desc=\"train\")\n",
    "            for batch in pbar:\n",
    "                loss = compute_loss(probe, batch, criterion,\n",
    "                                    entity_source=entity_source,\n",
    "                                    entity_layer=entity_layer,\n",
    "                                    editor_layer=editor_layer)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "                train_loss += loss.item()\n",
    "                pbar.set_description(f\"train [{loss.item():.2f}]\")\n",
    "            train_loss /= len(train_loader)\n",
    "\n",
    "            probe.eval()\n",
    "            val_loss = 0.\n",
    "            with torch.inference_mode():\n",
    "                pbar = tqdm(train_loader, desc=\"val\")\n",
    "                for batch in pbar:\n",
    "                    loss = compute_loss(probe, batch, criterion,\n",
    "                                        entity_source=entity_source,\n",
    "                                        entity_layer=entity_layer,\n",
    "                                        editor_layer=editor_layer)\n",
    "                    val_loss += loss.item()\n",
    "                    pbar.set_description(f\"val [{loss.item():.2f}]\")\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "\n",
    "            if stopper(val_loss):\n",
    "                probe.load_state_dict(best)\n",
    "                break\n",
    "            elif stopper.improved:\n",
    "                best = probe.state_dict()\n",
    "\n",
    "    return probe\n",
    "\n",
    "\n",
    "def test_probe(\n",
    "    probe,\n",
    "    test,\n",
    "    entity_source=ENTITY_SOURCE,\n",
    "    exclude_columns=(),\n",
    "    **kwargs\n",
    "):\n",
    "    probe.eval()\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    columns = data.column_names(test, exclude=exclude_columns)\n",
    "    with test.formatted_as(\"torch\", columns=columns):\n",
    "        loader = DataLoader(test, batch_size=BATCH_SIZE)\n",
    "        with torch.inference_mode():\n",
    "            for batch in tqdm(loader, desc=\"test\"):\n",
    "                predictions = forward(probe, batch, entity_source=entity_source, **kwargs)\n",
    "                y_true += get_labels(batch, entity_source=entity_source).bool().squeeze().tolist()\n",
    "                y_pred += torch.sigmoid(predictions).gt(.5).squeeze().tolist()\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f215ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, matthews_corrcoef\n",
    "\n",
    "for dataset_name, editor_layer, entity_layer in (\n",
    "    (\"counterfact\", 1, 26),\n",
    "    (\"biosbias\", 12, 15),\n",
    "):\n",
    "    layers = [editor_layer, entity_layer]\n",
    "    dataset = load_and_preprocess(dataset_name, split=\"train[:5000]\", layers=layers)\n",
    "    test = load_and_preprocess(dataset_name, split=\"train[5000:10000]\", layers=layers)\n",
    "    for version, entity_source in (\n",
    "        (\"prior\", \"prompt\"),\n",
    "        (\"med\", \"prompt_in_context\"),\n",
    "    ):\n",
    "        if dataset_name == \"biosbias\" and version == \"prior\":\n",
    "            continue\n",
    "        dataset = precompute_model_predictions(dataset_name, dataset, version=version)\n",
    "        test = precompute_model_predictions(dataset_name, dataset, version=version)\n",
    "        exclude_columns = [\"target_unmediated\"] if dataset_name == \"biosbias\" else []\n",
    "        probe = train_probe(\n",
    "            dataset,\n",
    "            entity_source=entity_source,\n",
    "            entity_layer=entity_layer,\n",
    "            editor_layer=editor_layer,\n",
    "            exclude_columns=exclude_columns,\n",
    "        )\n",
    "        y_true, y_pred = test_probe(\n",
    "            probe,\n",
    "            test,\n",
    "            entity_source=entity_source,\n",
    "            entity_layer=entity_layer,\n",
    "            editor_layer=editor_layer,\n",
    "            exclude_columns=exclude_columns,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            dataset_name,\n",
    "            version,\n",
    "            accuracy_score(y_true, y_pred),\n",
    "            f1_score(y_true, y_pred),\n",
    "            matthews_corrcoef(y_true, y_pred),\n",
    "        )\n",
    "        \n",
    "        y_true = [not y for y in y_true]\n",
    "        y_pred = [not y for y in y_pred]\n",
    "        print(\n",
    "            dataset_name,\n",
    "            version,\n",
    "            accuracy_score(y_true, y_pred),\n",
    "            f1_score(y_true, y_pred),\n",
    "            matthews_corrcoef(y_true, y_pred),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store these here for later.\n",
    "metrics = {\n",
    "    \"fact-med\": {\n",
    "        \"accuracy\": 0.982,\n",
    "        \"f1\": 0.970,\n",
    "        \"mcc\": 0.958,\n",
    "    },\n",
    "    \"fact-prior\": {\n",
    "        \"accuracy\": .914,\n",
    "        \"f1\": .598,\n",
    "        \"mcc\": 0.615,\n",
    "    },\n",
    "    \"bias-med\": {\n",
    "        \"accuracy\": .960,\n",
    "        \"f1\": .960,\n",
    "        \"mcc\": .920,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a700375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
