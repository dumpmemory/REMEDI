{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "from experiments.aliases import REMEDI_EDITOR_LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85095783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL = \"gptj\"\n",
    "\n",
    "RESULTS_ROOT = Path(\"../../results\")\n",
    "assert RESULTS_ROOT.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f03109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def load_json(file):\n",
    "    with file.open(\"r\") as handle:\n",
    "        return json.load(handle)\n",
    "\n",
    "\n",
    "remedi_layer = REMEDI_EDITOR_LAYER[MODEL][\"mcrae\"]\n",
    "experiment_name = f\"post_icml_eval_ent_mcrae_{MODEL}\"\n",
    "results_dir = RESULTS_ROOT / experiment_name\n",
    "\n",
    "results = load_json(results_dir / \"linear\" / str(remedi_layer) / \"entailment.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f694bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from remedi import data\n",
    "\n",
    "dataset = data.load_dataset(\"mcrae\", split=\"train[5000:10000]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554068d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "logp_diffs_co = defaultdict(list)\n",
    "logp_diffs_orig = defaultdict(list)\n",
    "logp_diffs_unrel = defaultdict(list)\n",
    "for result in results[\"samples\"]:\n",
    "    sid = result[\"id\"]\n",
    "    for features_key, diffs in (\n",
    "        (\"co_features\", logp_diffs_co),\n",
    "        (\"orig_features\", logp_diffs_orig),\n",
    "        (\"unrel_features\", logp_diffs_unrel),\n",
    "    ):\n",
    "        for feature in result[features_key]:\n",
    "            diffs[sid].append((feature[\"logp_post\"] - feature[\"logp_pre\"]) / abs(feature[\"logp_pre\"]))\n",
    "#             diffs[sid].append(np.exp(feature[\"logp_post\"]) - np.exp(feature[\"logp_pre\"]))\n",
    "\n",
    "for key, diffs in (\n",
    "    (\"co\", logp_diffs_co),\n",
    "    (\"orig\", logp_diffs_orig),\n",
    "    (\"unrel\", logp_diffs_unrel),\n",
    "):\n",
    "    values = [np.mean(ds) for ds in diffs.values()]\n",
    "    print(key, np.mean(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b220af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "features = [x[\"attribute\"] for x in dataset]\n",
    "Counter(features).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f043ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# We'll remove a couple disfluent or weird outliers.\n",
    "BANNED_FEATURES = frozenset({\n",
    "    \"is used long ago\"\n",
    "})\n",
    "\n",
    "sns.set()\n",
    "sns.set_style({'font.family':'serif', 'font.serif':['Times New Roman']})\n",
    "\n",
    "attribute = \"comes in bunches\"\n",
    "indices = [i for i, x in enumerate(dataset) if x[\"attribute\"] == attribute]\n",
    "\n",
    "logp_lm_by_co_feature = defaultdict(list)\n",
    "logp_human_by_co_feature = {}\n",
    "for index in indices:\n",
    "    for co_feature in results[\"samples\"][index][\"co_features\"]:\n",
    "        feature = co_feature[\"feature\"]\n",
    "        if feature in BANNED_FEATURES:\n",
    "            continue\n",
    "        logp_human_by_co_feature[feature] = co_feature[\"logp_ref\"]\n",
    "        logp_lm_by_co_feature[feature].append(co_feature[\"logp_post\"])\n",
    "logp_lm_by_co_feature = {key: np.mean(values) for key, values in logp_lm_by_co_feature.items()}\n",
    "\n",
    "features = sorted(logp_human_by_co_feature)\n",
    "xs = [logp_human_by_co_feature[feature] for feature in features]\n",
    "ys = [logp_lm_by_co_feature[feature] for feature in features]\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "for i, feature in enumerate(features):\n",
    "    ax.annotate(feature, (xs[i], ys[i]))\n",
    "ax.scatter(xs, ys)\n",
    "plt.title(attribute)\n",
    "plt.xlabel(\"Human Co-Occurrence logp\")\n",
    "plt.ylabel(\"Post-Edit LM logp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e886829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "index = 5\n",
    "n_samples = 15\n",
    "\n",
    "sample = dataset[index]\n",
    "result = results[\"samples\"][index]\n",
    "\n",
    "title = f'{sample[\"entity\"].capitalize()} + {sample[\"attribute\"]}'\n",
    "\n",
    "data = OrderedDict()\n",
    "for key, label in (\n",
    "    (\"co\", \"Entailed\"),\n",
    "    (\"orig\", \"Original\"),\n",
    "    (\"unrel\", \"Unrelated\"),\n",
    "):\n",
    "    features = result[f\"{key}_features\"][:n_samples]\n",
    "    before = [feature[\"logp_pre\"] for feature in features]\n",
    "    after = [feature[\"logp_post\"] for feature in features]\n",
    "    labels = [feature[\"feature\"] for feature in features]\n",
    "    data[label] = {\n",
    "        \"before\": before,\n",
    "        \"after\": after,\n",
    "        \"labels\": labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc9e348",
   "metadata": {},
   "source": [
    "An alternative visualization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda0882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "# attribute = \"is found on couches\"\n",
    "# attribute = \"lives by the ocean\"\n",
    "# attribute = \"has flashing lights\"\n",
    "# attribute = \"spins webs\"\n",
    "attribute = \"is used for chopping wood\"\n",
    "\n",
    "unrel_cutoff_logp = -30\n",
    "limit = 25\n",
    "\n",
    "title = r\"Effect of REMEDI($\\it{\" + attribute.replace(\" \", r\"\\ \") + \"}$)\"\n",
    "\n",
    "indices = [i for i, x in enumerate(dataset) if x[\"attribute\"] == attribute]\n",
    "\n",
    "corr = []\n",
    "orig = []\n",
    "unrel = []\n",
    "for index in indices:\n",
    "    for feature in results[\"samples\"][index][\"co_features\"]:\n",
    "        logp_pre = feature[\"logp_pre\"]\n",
    "        logp_post = feature[\"logp_post\"]\n",
    "        logp_ref = feature[\"logp_ref\"]\n",
    "        label = feature[\"feature\"]\n",
    "        corr.append([logp_pre, logp_post, logp_ref, label])\n",
    "\n",
    "    for feature in results[\"samples\"][index][\"orig_features\"]:\n",
    "        logp_pre = feature[\"logp_pre\"]\n",
    "        logp_post = feature[\"logp_post\"]\n",
    "        logp_ref = feature[\"logp_ref\"]\n",
    "        label = feature[\"feature\"]\n",
    "        orig.append([logp_pre, logp_post, logp_ref, label])\n",
    "\n",
    "    for feature in results[\"samples\"][index][\"unrel_features\"]:\n",
    "        logp_pre = feature[\"logp_pre\"]\n",
    "        logp_post = feature[\"logp_post\"]\n",
    "        label = feature[\"feature\"]\n",
    "        if logp_pre < unrel_cutoff_logp:\n",
    "            continue\n",
    "        unrel.append([logp_pre, logp_post, float(\"-inf\"), label])\n",
    "\n",
    "def apply_limit(values):\n",
    "    chosen = sorted(\n",
    "        values,\n",
    "#         key=lambda x: abs(x[1] - x[0])\n",
    "        key=lambda x: x[0]\n",
    "#         key=lambda x: (x[2], x[0])\n",
    "#         key=lambda x: x[1]\n",
    "        , reverse=True)[:limit]\n",
    "    return np.array([x[:2] for x in chosen]), [x[-1] for x in chosen]\n",
    "\n",
    "corr, corr_labels = apply_limit(corr[:limit])\n",
    "unrel, unrel_labels = apply_limit(unrel[:limit])\n",
    "orig, orig_labels = apply_limit(orig[:limit])\n",
    "\n",
    "print(corr[:, 1] - corr[:, 0])\n",
    "data = OrderedDict() \n",
    "\n",
    "# Version where labels are excluded.\n",
    "# corr_labels = [\"\"] * len(corr)\n",
    "# orig_labels = [\"\"] * len(orig)\n",
    "# unrel_labels = [\"\"] * len(unrel)\n",
    "\n",
    "# Version where deltas are shown.\n",
    "data[\"Correlated Features ($f^{(c)}$)\"] = {\n",
    "    \"before\": corr[:, 0],\n",
    "    \"after\": corr[:, 1],\n",
    "    \"labels\": corr_labels,\n",
    "}\n",
    "data[\"Original Features of Edited Concept ($f^{(o)}$)\"] = {\n",
    "    \"before\": orig[:, 0],\n",
    "    \"after\": orig[:, 1],\n",
    "    \"labels\": orig_labels\n",
    "}\n",
    "data[\"Random Features\"] = {\n",
    "    \"before\": unrel[:, 0],\n",
    "    \"after\": unrel[:, 1],\n",
    "    \"labels\": unrel_labels,\n",
    "}\n",
    "\n",
    "# Version where only diffs are shown.\n",
    "# data[\"Correlated\"] = {\n",
    "#     \"before\": corr[:, 1] - corr[:, 0],\n",
    "#     \"after\": corr[:, 1] - corr[:, 0],\n",
    "#     \"labels\": [\"\"] * len(corr),\n",
    "# }\n",
    "# data[\"Original\"] = {\n",
    "#     \"before\": orig[:, 1] - orig[:, 0],\n",
    "#     \"after\": orig[:, 1] - orig[:, 0],\n",
    "#     \"labels\": [\"\"] * len(orig)\n",
    "# }\n",
    "# data[\"Unrelated\"] = {\n",
    "#     \"before\": unrel[:, 1] - unrel[:, 0],\n",
    "#     \"after\": unrel[:, 1] - unrel[:, 0],\n",
    "#     \"labels\": [\"\"] * len(unrel),\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"dejavuserif\"\n",
    "\n",
    "ymin = -40\n",
    "ytext = -21\n",
    "\n",
    "def plot_subplot(ax, before, after, labels):\n",
    "    for i, (b, a, label) in enumerate(zip(before, after, labels)):\n",
    "        x = i - .5\n",
    "        color = 'darkblue' if b < a else \"red\"\n",
    "        ax.plot([x, x], [b, a], marker='o', color=color)\n",
    "        if abs(a - b) >= 1.5: \n",
    "            ax.annotate(\n",
    "                \"\",\n",
    "                xy=(x, a),\n",
    "                xytext=(x, b),\n",
    "                arrowprops=dict(arrowstyle=\"->\", lw=1.5, color=color),\n",
    "            )\n",
    "        if (\n",
    "            label\n",
    "            and len(label) < 25\n",
    "#             and i < 3 * len(labels) // 4\n",
    "            and i < 18\n",
    "            and i % 2 == 0\n",
    "        ):   \n",
    "            ax.plot([x, x], [min(a, b) - .5, ytext], linestyle=':', color='darkgrey')\n",
    "            ax.text(\n",
    "                x,\n",
    "                ytext,\n",
    "                label,\n",
    "                fontsize=14,\n",
    "                rotation=-45,\n",
    "                bbox=dict(facecolor='white', edgecolor='darkgrey', boxstyle='round,pad=0.2'),\n",
    "                va=\"top\",\n",
    "                ha=\"left\",\n",
    "            )\n",
    "\n",
    "        # Remove x-axis tick labels and y-axis ticks for subplots other than the leftmost one\n",
    "        ax.set_xticks([])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticks(np.arange(0, ymin - 1, -5))\n",
    "        \n",
    "        # Last label is a bit ugly, remove it.\n",
    "        labels = ax.get_yticklabels()\n",
    "        if labels:\n",
    "            labels[-1] = \"\"\n",
    "            ax.set_yticklabels(labels)\n",
    "\n",
    "# Create the subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, sharey=True, figsize=(18, 5))\n",
    "plt.suptitle(title, fontsize=18)\n",
    "\n",
    "# Plot data in subplots\n",
    "for ax, (key, values) in zip(axes, data.items()):\n",
    "    plot_subplot(ax, values['before'], values['after'], values['labels'])\n",
    "    ax.set_title(key, fontsize=16)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "axes[0].set_ylabel('$\\log p_{LM}(f \\mid c)$', fontsize=16)\n",
    "# axes[1].set_ylabel('$\\log p_M(f^{(o)})$', fontsize=16)\n",
    "# axes[2].set_ylabel('$\\log p_M(f)$', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('mcrae.pdf', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776fa3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda0d3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
