{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a5be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pickle\n",
    "\n",
    "bios_file = pathlib.Path('../biosbias/BIOS.pkl')\n",
    "with bios_file.open('rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93ab9ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': 'crawl-data/CC-MAIN-2013-20/segments/1368696381249/wet/CC-MAIN-20130516092621-00000-ip-10-60-113-184.ec2.internal.warc.wet.gz',\n",
       " 'raw': '* Nora Fisher Onar is an assistant professor of international relations at Bahcesehir University in Istanbul. She is also a Ronald D. Asmus Policy Entrepreneur Fellow with the German Marshall Fund and is a Visiting Fellow at the Centre for International Studies (CIS) at the University of Oxford. This commentary first appeared at Sada, an online journal published by the Carnegie Endowment for International Peace.',\n",
       " 'name': ('Nora', 'Fisher', 'Onar'),\n",
       " 'raw_title': 'assistant professor',\n",
       " 'gender': 'F',\n",
       " 'start_pos': 109,\n",
       " 'title': 'professor',\n",
       " 'URI': 'http://acturca.wordpress.com/2012/04/13/turkey-model-mideast/',\n",
       " 'bio': '_ is also a Ronald D. Asmus Policy Entrepreneur Fellow with the German Marshall Fund and is a Visiting Fellow at the Centre for International Studies (CIS) at the University of Oxford. This commentary first appeared at Sada, an online journal published by the Carnegie Endowment for International Peace.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17bf2b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'professor': 0,\n",
       "  'accountant': 1,\n",
       "  'journalist': 2,\n",
       "  'architect': 3,\n",
       "  'photographer': 4,\n",
       "  'psychologist': 5,\n",
       "  'teacher': 6,\n",
       "  'nurse': 7,\n",
       "  'attorney': 8,\n",
       "  'software_engineer': 9,\n",
       "  'painter': 10,\n",
       "  'physician': 11,\n",
       "  'chiropractor': 12,\n",
       "  'personal_trainer': 13,\n",
       "  'surgeon': 14,\n",
       "  'filmmaker': 15,\n",
       "  'dietitian': 16,\n",
       "  'dentist': 17,\n",
       "  'dj': 18,\n",
       "  'model': 19,\n",
       "  'composer': 20,\n",
       "  'poet': 21,\n",
       "  'comedian': 22,\n",
       "  'yoga_teacher': 23,\n",
       "  'interior_designer': 24,\n",
       "  'pastor': 25,\n",
       "  'rapper': 26,\n",
       "  'paralegal': 27},\n",
       " {'M': 0, 'F': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_indexer = {}\n",
    "for x in data:\n",
    "    title = x['title']\n",
    "    if title not in title_indexer:\n",
    "        title_indexer[title] = len(title_indexer)\n",
    "\n",
    "gender_indexer = {'M': 0, 'F': 1}\n",
    "\n",
    "title_indexer, gender_indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abd6d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e6c0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('roberta-base')\n",
    "model = transformers.AutoModelForMaskedLM.from_pretrained('roberta-base').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3710adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        bio = x['raw']\n",
    "        bio = bio[bio.index(x['name'][0]):]\n",
    "        mention = 1\n",
    "        return bio, title_indexer[x['title']], mention, gender_indexer[x['gender']]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "dataset = Dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "759270b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mieke Verbijlen is a photographer based in Antwerp, Belgium. Six years ago, she moved into the second floor of this old house along a tree-lined street with nice galleries nearby. As a collector of beautiful things with a love of second-hand pieces, Miekes style just fell into place. Shed love to have a couch, but her home is too small for that, and shed rather have the space open than make it f',\n",
       " 4,\n",
       " 1,\n",
       " 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "977373b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad991fafeaa34fedad18385471eb4167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/96576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for i in tqdm(range(len(dataset))):\n",
    "    dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7e5a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "412bf382b2aa41d0ab5425204db3dd6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch 0:   0%|          | 0/2717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-12f488ef0e25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'longest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mreps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmentions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model.to(device)\n",
    "probe = nn.Sequential(\n",
    "    nn.Linear(768, 768),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(768, len(title_indexer)),\n",
    ").to(device)\n",
    "optimizer = optim.AdamW(probe.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "val_size = int(.1 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train, val = torch.utils.data.random_split(dataset, (train_size, val_size))\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=32)\n",
    "\n",
    "bad, best, state_dict = 0, float('inf'), None\n",
    "for epoch in range(1):\n",
    "    description = f'epoch {epoch}'\n",
    "    progress = tqdm(train_loader, desc=description)\n",
    "\n",
    "    probe.train()\n",
    "    train_loss = 0\n",
    "    for sentences, targets, mentions, _ in progress:\n",
    "        inputs = tokenizer(list(sentences), return_tensors='pt', padding='longest').to(device)\n",
    "        outputs = model(**inputs, return_dict=True, output_hidden_states=True)\n",
    "        reps = outputs.hidden_states[-1][range(len(sentences)), sorted(mentions)]\n",
    "        predictions = probe(reps)\n",
    "        loss = criterion(predictions, targets.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        progress.set_description(f'{description} (loss={loss.item():.3f})')\n",
    "    train_loss /= len(train_loader)\n",
    "    print('train', train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "54630f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'On', 'Ġa', 'Ġhike', ',', 'Ġmy', 'Ġsurgeon', ',', 'ĠAlex', ',', 'Ġtold', 'Ġme', 'Ġabout', 'Ġhis', 'Ġmost', 'Ġrecent', 'Ġpatient', '.', 'ĠAlex', 'Ġhas', 'Ġan', 'ĠMD', 'Ġdegree', 'Ġfrom', 'ĠUCS', 'F', '.', 'ĠHe', 'Ġspecialized', 'Ġin', 'Ġcard', 'i', 'oth', 'or', 'ac', 'ic', 'Ġsurgery', '.', '</s>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'teacher'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_title_indexer = {index: title for title, index in title_indexer.items()}\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict(sentence, token=1):\n",
    "    inputs = tokenizer([sentence], return_tensors='pt', padding='longest').to(device)\n",
    "    print(tokenizer.convert_ids_to_tokens(inputs.input_ids.squeeze().tolist()))\n",
    "    outputs = model(**inputs, return_dict=True, output_hidden_states=True)\n",
    "    reps = outputs.hidden_states[-1][:, token]\n",
    "    predictions = probe(reps)\n",
    "    return reverse_title_indexer[predictions.argmax(dim=-1).squeeze().item()]\n",
    "\n",
    "predict('On a hike, my surgeon, Alex, told me about his most recent patient. Alex has an MD degree from UCSF. He specialized in cardiothoracic surgery.', token=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cdcfc0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767de6494a124468a2e3d573d56d024e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7147, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "@torch.inference_mode()\n",
    "def accuracy(dataset, probe=probe):\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=32)\n",
    "    correct = 0\n",
    "    for sentences, targets, mentions, _ in tqdm(loader):\n",
    "        inputs = tokenizer(list(sentences), return_tensors='pt', padding='longest').to(device)\n",
    "        outputs = model(**inputs, return_dict=True, output_hidden_states=True)\n",
    "        reps = outputs.hidden_states[-1][range(len(sentences)), mentions]\n",
    "        predictions = probe(reps).argmax(dim=-1).long()\n",
    "        correct += predictions.eq(targets.to(device)).sum()\n",
    "    return correct / len(dataset)\n",
    "\n",
    "print(accuracy(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 10-20 attributes, similar to this\n",
    "# Try with linear probes?\n",
    "# Belinda-style probe; dot bert REPs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
