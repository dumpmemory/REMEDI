{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b81b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pathlib\n",
    "\n",
    "file = pathlib.Path('probing-discourse.json')\n",
    "with file.open('r') as handle:\n",
    "    samples = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f700524e",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa04d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "device = 'cuda:1'\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert = transformers.AutoModelForMaskedLM.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a38797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "probe = torch.load('probe_wikidata_occupation.pth', map_location=device)\n",
    "indexer = torch.load('probe_wikidata_occupation_indexer.pth')\n",
    "unindexer = {index: label for label, index in indexer.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937c568",
   "metadata": {},
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35567217",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "loader = data.DataLoader(samples, batch_size=64)\n",
    "\n",
    "predictions = []\n",
    "for batch in tqdm(loader):\n",
    "    with torch.inference_mode():\n",
    "        inputs = tokenizer(batch['text'], return_tensors='pt', padding='longest').to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = bert(**inputs, return_dict=True, output_hidden_states=True)\n",
    "            reps = outputs.hidden_states[-1][:, 6]\n",
    "            topks = probe(reps).topk(k=5, dim=-1).indices.tolist()\n",
    "        predictions.extend([\n",
    "            [unindexer[idx] for idx in topk]\n",
    "            for topk in topks\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9f2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "accuracies = collections.defaultdict(list)\n",
    "for sample, topk in zip(samples, predictions):\n",
    "    if sample['condition']['name'] != 'real' and sample['condition']['occupation'] == 'real':\n",
    "        continue\n",
    "    condition = frozenset(sample['condition'].items())\n",
    "    accuracies[condition].append(sample['labels']['occupation'] in topk)\n",
    "accuracies = {cond: sum(values) / len(values) for cond, values in accuracies.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6ffbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import tabulate\n",
    "\n",
    "table = [('context', 'name', 'occupation', 'accuracy')]\n",
    "for keys, accuracy in sorted(accuracies.items(), key=lambda kv: kv[-1], reverse=True):\n",
    "    keys = dict(keys)\n",
    "    row = [keys['context'], keys['name'], keys['occupation'], f'{accuracy:.3f}']\n",
    "    table.append(row)\n",
    "\n",
    "\n",
    "table_file = pathlib.Path('accuracy_table.txt')\n",
    "with table_file.open('w') as handle:\n",
    "    handle.write(tabulate.tabulate(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a4888",
   "metadata": {},
   "source": [
    "# Connect with causal predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd435ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "loader = data.DataLoader(samples, batch_size=64)\n",
    "\n",
    "probe_predictions, model_predictions = [], []\n",
    "for batch in tqdm(loader):\n",
    "    with torch.inference_mode():\n",
    "        inputs = tokenizer(batch['text'], return_tensors='pt', padding='longest').to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = bert(**inputs, return_dict=True, output_hidden_states=True)\n",
    "            reps = outputs.hidden_states[-1][:, 6]\n",
    "            probe_topks = probe(reps).topk(k=5, dim=-1).indices.tolist()\n",
    "        probe_predictions.extend([\n",
    "            [unindexer[idx] for idx in topk]\n",
    "            for topk in probe_topks\n",
    "        ])\n",
    "\n",
    "        texts = [\n",
    "            f'{text} Therefore, {name} works as a [MASK].'\n",
    "            for text, name in zip(batch['text'], batch['labels']['name'])\n",
    "        ]\n",
    "        inputs = tokenizer(texts, return_tensors='pt', padding='longest').to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = bert(**inputs, return_dict=True, output_hidden_states=True)\n",
    "        batch_idx = torch.arange(len(texts))\n",
    "        token_idx = inputs.attention_mask.sum(dim=-1) - 3\n",
    "        model_predictions_ids = outputs.logits[batch_idx, token_idx].argmax(dim=-1)\n",
    "        model_predictions_tokens = tokenizer.batch_decode(model_predictions_ids.tolist())\n",
    "        model_predictions.extend(model_predictions_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8ddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "probe_accuracies = collections.defaultdict(list)\n",
    "model_accuracies = collections.defaultdict(list)\n",
    "probe_model_agreements = collections.defaultdict(list)\n",
    "for sample, model_pred, probe_topk in zip(samples, model_predictions, probe_predictions):\n",
    "    if sample['condition']['name'] != 'real' and sample['condition']['occupation'] == 'real':\n",
    "        continue\n",
    "    condition = frozenset(sample['condition'].items())\n",
    "    probe_accuracies[condition].append(sample['labels']['occupation'] in probe_topk)\n",
    "    model_accuracies[condition].append(sample['labels']['occupation'] == model_pred)\n",
    "    probe_model_agreements[condition].append(model_pred in probe_topk)\n",
    "probe_accuracies = {cond: sum(values) / len(values) for cond, values in probe_accuracies.items()}\n",
    "model_accuracies = {cond: sum(values) / len(values) for cond, values in model_accuracies.items()}\n",
    "probe_model_agreements = {cond: sum(values) / len(values) for cond, values in probe_model_agreements.items()}\n",
    "\n",
    "table = [('context', 'name', 'occupation', 'probe accuracy', 'model accuracy', 'agreement')]\n",
    "for keys in sorted(probe_accuracies.keys()):\n",
    "    probe_accuracy = probe_accuracies[keys]\n",
    "    model_accuracy = model_accuracies[keys]\n",
    "    agreement = probe_model_agreements[keys]\n",
    "\n",
    "    keys = dict(keys)\n",
    "    row = [keys['context'], keys['name'], keys['occupation'], f'{probe_accuracy:.3f}', f'{model_accuracy:.3f}',\n",
    "           f'{agreement:.3f}']\n",
    "    table.append(row)\n",
    "\n",
    "\n",
    "table_file = pathlib.Path('accuracy_table.txt')\n",
    "with table_file.open('w') as handle:\n",
    "    handle.write(tabulate.tabulate(table))\n",
    "print(tabulate.tabulate(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b56dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
